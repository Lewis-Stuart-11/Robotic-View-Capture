#!/usr/bin/env python3

import time
import json
import os
import numpy as np
import configargparse

from geometry_msgs.msg import Point 

from trajectory_handler import TrajectoryHandler
from robot_control import RobotControl
from quartonian_handler import QuartonianHandler
from db_handler import ImgCaptureDatabaseHandler

# Lambda functions for converting world units to robot units (based on the robot's reach)
rc_to_wc = None
wc_to_rc = None

# Up vector for the environment 
up = Point(0, 0, 1.0)

# Accepts a list of three values and returns a ros Point object
def convert_list_to_point(point_list: list, convert_coords: bool=False) -> Point:

    # Converts world coordinates to robot coordinates
    if convert_coords:
        point_list = [wc_to_rc(point) for point in point_list]
    
    # Instantiates a new point from a list
    return Point(point_list[0], point_list[1], point_list[2])

# Takes a snapshot from the current camera
def take_snapshot(current_pos_idx: int):
    return str(current_pos_idx) + ".png"

# Creates all required objects inside of the MoveIt environment
def generate_objects(robot, args):

    # Creates the main object to capture in the environment with box size
    robot.add_box_to_scene("main_obj", args.main_obj_position, args.main_obj_size, attach=False)

    # Creates and attaches camera on the end of the robot arm
    robot.add_box_to_scene("camera", args.starting_position, args.camera_size, attach=True)
    
    # If a stand is to be autogenerated (use if not part of the URDF file)
    if args.auto_add_obj_stand:
        
        # Avoids the main object memory being overwritten
        stand_position = convert_list_to_point([args.main_obj_position.x, 
                                                args.main_obj_position.y, 
                                                args.main_obj_position.z])
        
        stand_size = [0.07, 0.07, stand_position.z]
        stand_position.z /= 2 

        robot.add_box_to_scene("stand", stand_position, stand_size, attach=False)

    # If set, will include extra scene objects defined in the object scene file
    if args.include_extra_obj:
        with open(args.scene_objs, "r") as scene_file:
            json_file = json.load(scene_file)

            objects = json_file["objects"]
            
            # Loops through each of the specified objects in the object file
            for object in objects:

                # Converts position and size to RC coordinates
                obj_pos = convert_list_to_point(object["position"], convert_coords=True)
                obj_size = [wc_to_rc(size) for size in object["size"]]

                # Adds the defined object type to the environment
                if object["type"] == "mesh":
                    robot.add_mesh_to_scene(object["name"], obj_pos, obj_size,
                                            object["mesh_file_name"], attach=bool(object["attach"]),)
                elif object["type"] == "box":
                    robot.add_box_to_scene(object["name"], obj_pos, obj_size, 
                                            attach=True if "attach" in object.keys() else False)
                elif object["type"] == "sphere":
                    robot.add_sphere_to_scene(object["name"], obj_pos, obj_size, 
                                            attach=True if "attach" in object.keys() else False)
                else:
                    raise Exception("Object type " + object["type"] + " is not currently supported")


# Configues the arguments added by the user
def config_parser():

    parser = configargparse.ArgumentParser()

    # Config Handling
    parser.add_argument("--config", is_config_file=True, help="Config file path")
    parser.add_argument("--log_dir", type=str, default="", help="Log file path")
    parser.add_argument("--experiment_name", type=str, required=True, help="Name of this experiment iteration")
    parser.add_argument("--print", action="store_true", default=False, help="Print useful info to stdout")
    parser.add_argument("--visualise", action="store_true", default=False, help="Generate scatter diagrams of positions")
    parser.add_argument("--save_fig", action="store_true", default=False, help="Whether to save the generated visualisation")
    
    # Database Handling
    parser.add_argument("--save_to_db", action="store_true", default=False, help="Whether to save experiment to database")
    parser.add_argument("--continue_experiment", action="store_true", default=False, 
                        help="Whether to continue training an experiment if the name already exists in the database")
    parser.add_argument("--replace_stored_experiment", action="store_true", default=False, 
                        help="Whether to replace the stored experiment or increment the current experiment name")

    # Scene Objects
    parser.add_argument("--main_obj_position", type=float, action="append", default=[], required=True,
                        help="The object position in relation to the base position (cm)")
    parser.add_argument("--main_obj_size", type=float,  action="append", default=[], required=True,
                        help="The estimated size of the object in length (x), width (y) and height (z)")
    parser.add_argument("--starting_position", type=float, action="append", default=[], required=True,
                        help="The object starting position in relation to the base position (cm)")
    
    parser.add_argument("--auto_add_obj_stand", action="store_true", default=False,
                        help="Automatically adds the object stand based on its starting position")
    parser.add_argument("--include_extra_obj", action="store_true", default=False,
                        help="Set to allow extra objects to be added from json object file")
    parser.add_argument("--scene_objs", type=str, default="", help="Object JSON file path")

    # Camera Properties
    parser.add_argument("--camera_size", type=float, action="append", default=[], required=True,
                        help="Size of the camera in: width, depth, height (cm)")
    parser.add_argument("--camera_focal_length", type=float, default=None, required=True,
                        help="Focal length of the camera being used")

    # View Generation
    parser.add_argument("--rings", type=int, default=7, 
                         help="The number of rings in the generated sphere of capture views")
    parser.add_argument("--sectors", type=int, default=14, 
                         help="The number of sectors in the generated sphere of capture views")
    parser.add_argument("--capture_radius", type=float, required=True,
                        help="The distance of the camera to the origin when calculating views (cm)")

    # Movement Handling
    parser.add_argument("--planning_time", type=float, default=3.0, 
                         help="Number of seconds per planning attempt")
    parser.add_argument("--planning_algorithm", type=str, default=None, 
                        help="The name of the path planning algorithm to use")
    parser.add_argument("--num_move_attempts", type=int, default=2, 
                         help="Number of move attempts before moving to next position in queue")
    parser.add_argument("--retry_failed_pos", action="store_true", default=False,
                         help="Set to attempt to move to previously failed positions")
    
    # Robot RC Settings (default for UR5 robot)
    parser.add_argument("--restricted_x", type=float, default=0.05, help="Minumum X value for a self-collision")
    parser.add_argument("--restricted_y", type=float, default=0.05, help="Minumum Y value for a self-collision")
    parser.add_argument("--restricted_z", type=float, default=-0.1, help="Minumum Z value for a self-collision")
    parser.add_argument("--max_dist", type=float, default=1, 
                        help="Maximum distance from base for robotic reach (normally always 1)")

    # Robot WC Settings (default for UR5 robot)
    parser.add_argument("--max_reach", type=float, default=85, 
                        help="Maximum distance from base for robotic reach (cm)")

    args = parser.parse_args()

    # Converst real world coordinates into robot coordinates
    global rc_to_wc, wc_to_rc
    rc_to_wc = lambda x: float(x) * float(args.max_reach) 
    wc_to_rc = lambda x: float(x) / float(args.max_reach) 

    # Number of move attempts must be larger than 0
    if args.num_move_attempts <= 0:
        raise Exception("Number of move attempts must be larger than 0")
    

    # Stores the positions in the correct object format
    args.main_obj_position = convert_list_to_point(args.main_obj_position, convert_coords=True)
    args.starting_position = convert_list_to_point(args.starting_position, convert_coords=True)

    # Values are converted into the correct coordinate system
    args.camera_size = [wc_to_rc(camera_dim) for camera_dim in args.camera_size]
    args.main_obj_size = [wc_to_rc(obj_dim) for obj_dim in args.main_obj_size]
    args.capture_radius = wc_to_rc(args.capture_radius)

    return args

# Creates and saves the experiment in the database depending on the user arguments
def save_experiment_in_db(args, db_handler, experiment_name):

    # Checks if the experiment already exists in the database
    if db_handler.get_experiment_with_name(experiment_name):
        if not args.continue_experiment:

            # If the experiment should not be replaced, then create a new experiment
            # with the same name but with an incrementation at the end of the name
            if not args.replace_stored_experiment:
                db_name_i = 1
                experiment_name += "_" + str(db_name_i)

                while db_handler.get_experiment_with_name(experiment_name):
                    experiment_name = experiment_name[:-1]
                    experiment_name += str(db_name_i)
                    db_name_i+= 1
            
            # Otherwise remove all existing data for that experiment 
            else:
                db_handler.remove_experiment_with_name(experiment_name)

            db_handler.create_new_experiment(experiment_name, args.main_obj_position, args.main_obj_size, 
                                            args.capture_radius, args.rings, args.sectors)
        
        # If the experiment should be continued, then set the current experiment to the saved experiment
        # with the same name as the experiment name arguement 
        else:
            db_handler.set_current_experiment(experiment_name)
    
    # If the experiment is not currently stored in the database, then add it and continue 
    else:
        db_handler.create_new_experiment(experiment_name, args.main_obj_position, args.main_obj_size, 
                                            args.capture_radius, args.rings, args.sectors)

    return db_handler


def capture_view(view_id, robot, quartonian_handler):
    print("Successfully moved arm to new position")
    file_name = take_snapshot(view_id)
    print("View Captured")

    # Gets transformation matrix from the world to the end of the robot arm
    translation, rotation = robot.get_total_transform()
    trans_matrix = quartonian_handler.get_tranformation_matrix_from_transform(translation, rotation)
    
    # Generates the appropraite view data
    view_data = {"file_path": file_name,
                    "transformation_matrix": np.array2string(trans_matrix, precision=14, separator=",")}
    
    return view_data


def run_view_capture(args, robot, trajectory_handler, db_handler, quartonian_handler):

    # Stores all data for view captureing (can be recreated in a view synthesis model)
    transform_data = {"frames": [], "focal_length": args.camera_focal_length}

    # Gets the current position for the robot to traverse to and continues to loop until no more 
    # positions in the queue
    for current_pos_idx, current_pos in trajectory_handler.get_next_positions():
        print(str(current_pos_idx))

        # Checks if this point has been previously successfully traversed for the saved experiment
        # If so, and the experiment should be continued, then skip this position 
        if args.save_to_db and args.continue_experiment:
            current_point = db_handler.get_point_with_num(current_pos_idx)

            if current_point is not None and current_point[2] == 1 and current_point[3] == 1:
                print("Point has already been traveresed previously, skipping...")
                continue

        print("Attempting to move to position: " + str(current_pos.x) + ", " + str(current_pos.y) + ", " + str(current_pos.z))

        # Get rotation quaronian for the current position to point robot arm to the object origin
        quartonian = quartonian_handler.QuaternionLookRotation(quartonian_handler.SubtractVectors(args.main_obj_position, current_pos), up)

        # Move arm to position and rotate to point towards object origin
        success = robot.move_and_orientate_arm(current_pos, quartonian)

        # If successfully moved, then capture current view and add to transform data
        if success:
            view_data = capture_view(current_pos_idx, robot, quartonian_handler)
            transform_data["frames"].append(view_data)
    
            joint_info = robot.get_current_joint_info()

        else:
            print ("Unable to move arm to position after " + str(args.num_move_attempts) + " attempts")
        
        # If experimetn should be saved, then update position status 
        if args.save_to_db:
            db_handler.update_point_status(current_pos_idx, success)

        print()
        
        # Update position verdict in trajectory handler so the position will not be traversed again
        trajectory_handler.pos_verdict(current_pos_idx, success)

        time.sleep(0.5)

    # Reattempt to traverse to old positions, if set in the arguments 
    if args.retry_failed_pos:
        print("Retrying previously failed positions")
        print()

        # Gets the current previously failed position for the robot to traverse to and continues to loop 
        # until no more positions in the queue
        for current_pos_idx, current_pos in trajectory_handler.get_failed_positions():
            print(str(current_pos_idx))
            print("Reattempting to move to position: " + str(current_pos.x) + ", " + str(current_pos.y) + ", " + str(current_pos.z))

            # Get rotation quaronian for the current position to point robot arm to the object origin
            quartonian = quartonian_handler.QuaternionLookRotation(quartonian_handler.SubtractVectors(args.main_obj_position, current_pos), up)

            # If successfully moved, then capture current view and add to transform data
            if robot.move_and_orientate_arm(current_pos, quartonian):
                view_data = capture_view(current_pos_idx, robot, quartonian_handler)
            
                transform_data["frames"].append(view_data)
                
                # Update position status in the database
                if args.save_to_db:
                    db_handler.update_point_status(current_pos_idx, True)
            else:
                print("Unable to move arm to position after " + str(args.num_move_attempts) + " attempts")

            print()

    print("View capture finished")

    db_handler.close_database()

    # Positions are saved to log
    trajectory_handler.save_positions()

    # All positions are shown in a scatter graph, with validity being expressed in the colours
    if args.visualise:
        trajectory_handler.visualise_traversed_points(save=args.save_fig)


def main():

    args = config_parser()

    # Experiment name is converted into a file-friendly format
    experiment_name_condensed = args.experiment_name.replace(" ", "_").lower()

    experiment_file_name = os.path.join(args.log_dir, experiment_name_condensed)

    print("Experiment: " + experiment_name_condensed)

    # Handles all positions that the robot needs to traverse to  
    trajectory_handler = TrajectoryHandler(args.restricted_x, args.restricted_y, 
                                           args.max_dist, args.restricted_z, 
                                           save_directory=experiment_file_name)

    # Calculates all camera view positions in the scene based on where the object is and the number
    # of required views to be captured
    trajectory_handler.calculate_sphere_points(args.main_obj_position, 
                                               args.capture_radius, 
                                               rings=args.rings, sectors=args.sectors)

    print(str(len(trajectory_handler.predicted_positions["invalid_positions"])) + " different positions have been evaluated as invalid! ")

    # Shows a scatter diagram of the calculated valid and invalid positions in the scene
    if args.visualise:
        trajectory_handler.visualise_predicted_valid_points(save=args.save_fig)

    db_handler = None

    # If the experiment should be saved, then create a new database record for the experiment
    if args.save_to_db:

        db_handler = ImgCaptureDatabaseHandler(args.log_dir)

        db_handler = save_experiment_in_db(args, db_handler, experiment_name_condensed)

    # Handles all control of the UR5 and Scene
    robot = RobotControl(num_move_attempts=args.num_move_attempts,
                         planning_time=args.planning_time,
                         planning_algorithm=args.planning_algorithm)

    # Handles all vectors and quaronian logic for the robot
    quartonian_handler = QuartonianHandler()

    continue_process = input()
    if continue_process == "exit":
        exit()

    # Attempts to moves arm to the set starting position
    if robot.move_arm(args.starting_position):
        print("Moved robot to starting position, adding scene objects")
    else:
        raise Exception("Failed to move robot to starting position")

    # Generates all the required objects in the scene to ensure no collisions occur
    generate_objects(robot, args)

    print("Beginning capturing...")

    # Attempts view capturing of all generated positions and saves transforms
    transform_data = run_view_capture(args, robot, trajectory_handler, db_handler, quartonian_handler)

    # Transform data is saved to transform log file 
    with open(experiment_file_name+"_transforms.txt", "w") as save_file:
        json.dump(transform_data, save_file)

if __name__ == '__main__':
  main()
